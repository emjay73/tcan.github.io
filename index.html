<style type="text/css">
	body {
		/* font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;  */
		font-family: "Noto Sans";
		font-weight: 300;
		font-size: 18px;
		margin-left: auto;
		margin-right: auto;
		width: 1200px;
	}

	h1 {
		font-size: 32px;
		font-weight: 300;
	}

	.disclaimerbox {
		background-color: #eee;
		border: 1px solid #eeeeee;
		border-radius: 10px;
		-moz-border-radius: 10px;
		-webkit-border-radius: 10px;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 0px solid black;
		border-radius: 0px;
		-moz-border-radius: 0px;
		-webkit-border-radius: 0px;
	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px;
		-moz-border-radius: 10px;
		-webkit-border-radius: 10px;
	}

	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px;
		-moz-border-radius: 10px;
		-webkit-border-radius: 10px;
	}

	a:link,
	a:visited {
		color: #1367a7;
		text-decoration: none;
	}

	a:hover {
		color: #208799;
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big {
		/* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
			0px 0px 1px 1px rgba(0, 0, 0, 0.35),
			/* The top layer shadow */
			5px 5px 0 0px #fff,
			/* The second layer */
			5px 5px 1px 1px rgba(0, 0, 0, 0.35),
			/* The second layer shadow */
			10px 10px 0 0px #fff,
			/* The third layer */
			10px 10px 1px 1px rgba(0, 0, 0, 0.35),
			/* The third layer shadow */
			15px 15px 0 0px #fff,
			/* The fourth layer */
			15px 15px 1px 1px rgba(0, 0, 0, 0.35),
			/* The fourth layer shadow */
			20px 20px 0 0px #fff,
			/* The fifth layer */
			20px 20px 1px 1px rgba(0, 0, 0, 0.35),
			/* The fifth layer shadow */
			25px 25px 0 0px #fff,
			/* The fifth layer */
			25px 25px 1px 1px rgba(0, 0, 0, 0.35);
		/* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big {
		/* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
			0px 0px 1px 1px rgba(0, 0, 0, 0.35);
		/* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper {
		/* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
			0px 0px 1px 1px rgba(0, 0, 0, 0.35),
			/* The top layer shadow */
			5px 5px 0 0px #fff,
			/* The second layer */
			5px 5px 1px 1px rgba(0, 0, 0, 0.35),
			/* The second layer shadow */
			10px 10px 0 0px #fff,
			/* The third layer */
			10px 10px 1px 1px rgba(0, 0, 0, 0.35);
		/* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}

	hr {
		border: 0;
		height: 1.5px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 1.0), rgba(0, 0, 0, 0));
	}

	/* emjay added (start) */
	.checkmark-list {
		list-style-type: none;
		/* Remove default bullets */
		font-size: 17px;
		padding-left: 0;
		/* Remove default padding */
		margin-left: 0;
		/* Remove default margin */
	}

	.checkmark-list>li:before {
		content: '\2713';
		/* Unicode character for checkmark */
		margin-right: 8px;
		color: black;
		/* Optional: change checkmark color */
	}

	.checkmark-list ul {
		padding-left: 0;
		/* Remove default padding from nested lists */
		margin-left: 40px;
		/* Indent nested lists */
		list-style-type: none;
		/* Remove bullets from nested lists */
	}

	.checkmark-list ul>li:before {
		content: '\2713';
		/* Unicode character for checkmark */
		margin-right: 8px;
		color: black;
		/* Optional: change checkmark color for nested items */
	}

	.spaced-heading {
		margin-top: 20px;
		/* Adjust the value to increase or decrease space */
	}

	.figure-cell {
		padding-bottom: 40px;
		/* Adjust the value to increase or decrease space */
	}

	/* emjay added (end) */

	.icon {
		display: inline-block;
		width: 36px;
		/* Adjust as needed */
		height: 36px;
		/* Adjust as needed */
		/* background-image: url('./resources/Favicon.ico'); */
		background-image: url('./resources/images/can.png');
		background-size: contain;
		/* Ensure the SVG fits within the span */
		background-repeat: no-repeat;
		/* Prevent tiling */
		vertical-align: middle;
		/* Align with the text */
	}

	.icon-button {
		display: inline-block;
		width: 20px;
		/* Adjust as needed */
		height: 20px;
		/* Adjust as needed */
		/* background-image: url('./assets/arxiv_logo.svg'); */
		background-size: contain;
		/* Ensure the SVG fits within the span */
		background-repeat: no-repeat;
		/* Prevent tiling */
		vertical-align: bottom;
		/* Align with the text */
	}

	.noto-sans-<uniquifier> {
		font-family: "Noto Sans", sans-serif;
		font-optical-sizing: auto;
		font-weight: <weight>;
		font-style: normal;
		font-variation-settings:
			"wdth" 100;
	}

	.link-btn{
		background-color: #3c3939;
		padding: 7px 13px;
		border-radius: 20px;
		margin-top: 0px;
        margin-left: 2px;
        margin-right: 2px;
		color: white;
	}
	.link-btn:visited{
		color: white;
	}
</style>

<html>

<head>
	<title> <b>TCAN: Animating Human Images with Temporally Consistent Pose Guidance Using Diffusion Models</b></title>
	<!-- <meta property="og:image" content="./resources/vegs_icon.png" /> -->
	<!-- <meta property="og:image" content="./resources/images/can.png" /> -->
	<!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title"
		content="TCAN: Animating Human Images with Temporally Consistent Pose Guidance Using Diffusion Models" />
	<meta property="og:description" content="Pose-driven human-image animation diffusion models have shown the remarkable capability of realistic human video synthesis. 
	Despite the promising results achieved by previous approaches, challenges
	persist in achieving temporally consistent animation and ensuring robustness 
	against off-the-shelf pose detectors. In this paper, we present	TCAN, 
	the pose-driven human image animation method robust to erroneous pose and consistent over time. 
	In contrast to previous methods, we utilize the pre-trained ControlNet without fine-tuning to leverage its
	pre-acquired knowledge from a vast amount of pose-image-caption pairs.
	To keep the ControlNet frozen, we adapt LoRA to UNet layers, enabling 
	the network to align the latent space between the pose and appearance
	features. Additionally, by introducing an additional temporal layer to the
	ControlNet, we enhance robustness with respect to outliers of the pose
	detector. Extensive experiments demonstrate that the proposed method
	can achieve promising results in video synthesis tasks, encompassing various poses.
" />

	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
	<link rel="preconnect" href="https://fonts.googleapis.com">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link href="https://fonts.googleapis.com/css2?family=Noto+Sans:ital,wght@0,100..900;1,100..900&display=swap"
		rel="stylesheet">
	<link rel="icon" href="./resources/Favicon.ico">
	<link rel="stylesheet" href="./definitive-image-comparison-slider-master/src/dics.css">
	<script src="./definitive-image-comparison-slider-master/src/dics.js"></script>

	<link rel="stylesheet" href="./definitive-image-comparison-slider-master/src/dics.css">
	<script src="./definitive-image-comparison-slider-master/src/dics.js"></script>


	<script>
		document.addEventListener('DOMContentLoaded', domReady);

		function domReady() {

			var b = document.querySelectorAll('.b-dics');
			b.forEach(element =>
				new Dics({
					container: element,
					textPosition: 'top'
				})
			);

		}
	</script>

</head>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

<body>
	<br>
	<center>

		<table align=center width=1200px>
			<table align=center width=1200px>
				<tr>
					<td align=center width=300px>
						<center>
							<span class="icon"></span> <!-- Add this line to include the icon -->
							<span style="font-size:36px"> TCAN: Animating Human Images with
								<br>
								Temporally Consistent Pose Guidance Using Diffusion Models</span>
						</center>
					</td>
				</tr>
				<tr>
					<td align=center width=300px>
						<center>
							<span style="font-size:24px">ECCV 24</span>
						</center>
					</td>
				</tr>
			</table>
		</table>

		<br>

		<table align=center width=1200px>
			<table align=center width=900px>
				<tr>
					<td align=center width=300px>
						<center>
							<span style="font-size:24px"><a href="https://github.com/rlawjdghek">Jeongho Kim*</a></span>
							<br>
							<span style="font-size:14px">KAIST</span>
						</center>
					</td>
					<td align=center width=300px>
						<center>
							<span style="font-size:24px"><a href="https://vegs3d.github.io">Min-Jung Kim*</a></span>
							<br>
							<span style="font-size:14px">KAIST</span>
						</center>
					</td>
					<td align=center width=300px>
						<center>
							<span style="font-size:24px"><a href="https://ssuhan.github.io/">Junsoo Lee</a></span>
							<br>
							<span style="font-size:14px">Naver</span>
						</center>
					</td>
					<td align=center width=300px>
						<center>
							<span style="font-size:24px"><a href="https://sites.google.com/site/jaegulchoo">Jaegul
									Choo</a></span>
							<br>
							<span style="font-size:14px">KAIST</span>
						</center>
					</td>
				</tr>
			</table>
			
			<table align=center width=600px>
				<tr>
					<td align=center width=600px>
						<center>
							<span style="font-size:14px">(*: equal contribution)</span>
						</center>
					</td>
				</tr>
			</table>
		</table>
	</center>
	<center>
		<table>
			<tr style="height: 60px;">
                <td align=center> <span style="font-size:12pt">
                    <center>
                        <a class="link-btn" href=""> <img src="assets/pdf-logo.svg" class="icon-button" alt="icon-pdf"> &nbsp Paper</a>
                    </center>
            </td>
				<td align=center> <span style="font-size:12pt">
						<center>
							<a class="link-btn" href=""> <img src="assets/arxiv-logomark-small-white.svg" class="icon-button" alt="icon-arxiv"> &nbsp arXiv</a>
						</center>
				</td>
				<td align=center> <span style="font-size:12pt">
						<center>
							<a class="link-btn" href=""> <img src="assets/github-mark-white.svg" class="icon-button" alt="icon-github"> &nbsp Code</a>
						</center>
				</td>
				<!-- <td align=center> <span style="font-size:12pt">
                    <center>
                        <a class="link-btn" href="https://www.cvlibs.net/datasets/kitti-360/"> <img src="assets/pics-icon.svg" class="icon-button" alt="icon-Data"> &nbsp Data (KITTI-360)</a>
                    </center>
            	</td> -->
			</tr>
		</table>
	</center>
	<!-- <center>
		<table>
			<tr>
				<td align=center> <span style="font-size:18pt">
						<center>
							<a href="https://arxiv.org/abs/2103.03231">| ArXiv |</a>
						</center>
				</td>
				<td align=center> <span style="font-size:18pt">
						<center>
							<a href="https://youtu.be/u9HqKGqvJhQ?t=5843">| Code |</a>
						</center>
				</td>
			</tr>
		</table>
	</center> -->

	<center>
		<table align=center width=1000px>
			<h2 style="color:dimgrey;">Motion Transfer To Various Identities</h2> 
			<!-- <tr>
				<td>
					<center>
						<span style="font-size:16px"><b>Our method aligns and flattens Gaussian covariances to scene
								surfaces estimated from monocular normal prediction network</b></span>
					</center>
				</td>
			</tr>
			<br> -->
			<tr>
				<td width=1200px>
					<center>
						<video controls autoplay muted loop>
							<!-- <source src="./resources/videos/final_evs_demo_v4.mp4" type="video/mp4"> -->
							<source src="./resources/videos/comparison_tiktok_1200.mp4" type="video/mp4">
							
							Your browser does not support the video tag.
						</video>
					</center>
				</td>
			</tr>
			

		</table>
	</center>

	<!-- <center>
		<table align=center width=1200px>
			<tr>
				<td width=1200px>
					<center>
						<video controls autoplay muted loop>
							<source src="./resources/videos/3_render_0_0_0_less_small.mp4" type="video/mp4">
							Your browser does not support the video tag.
						  </video>
					</center>
				</td>
			</tr>
			<br>
			<tr>
				<td>
					<center>
					<span style="font-size:15px"><b>Our method jointly reconstructs static scene with dynamic object such as cars, which can then be relocated arbitrarily</b></span>
					</center>
				</td>
			</tr>
		</table>
	</center> -->

	<br>
	<!-- <center>
		<table align=center width=1200px>
			<tr>
				<td align=center width=1200px>
					<span style="font-size:20px">
											
						Our method can transfer motion information to various identities, including animation characters.  
						<br>Although the proportion of the animation is differ from that of the human, the motion is effectively transmitted. 
					</span>
				</td>
			</tr>
		</table>
	</center> -->
	<center>
		<table align=center width=1200px>
			<h2 style="color:dimgrey;">Motion Transfer To Animation Characters</h2> 
			<tr>
				<td width=1200px>
					<center>
						<video controls autoplay muted loop>
							<source src="./resources/videos/comparison_online_1200.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</center>
				</td>
				<!-- <td width=600px>
					<center>
						<video controls autoplay muted loop>
							<source src="./resources/videos/3_render_0_0_0_dynamic_small.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</center>
				</td>
				<td width=600px>
					<center>
						<video controls autoplay muted loop>
							<source src="./resources/videos/5_render_0_0_0_small.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</center>
				</td> -->
			</tr>

			<!-- <tr>
				<td width=600px>
					<center>
						<video controls autoplay muted loop>
							<source src="./resources/videos/render_0_0_0_small.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</center>
				</td>
				<td width=600px>
					<center>
						<video controls autoplay muted loop>
							<source src="./resources/videos/2_render_0_0_0_small.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</center>
				</td>
			</tr> -->
		</table>
	</center>
	<center>
		<table align=center width=1200px>
			<h2 style="color:dimgrey;">Additional Results</h2> 
			<tr>
				<td>
					<center>
						<video width="300" controls autoplay muted loop>
							<source src="./resources/videos/media6.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</center>
				</td>
				<td>
					<center>
						<video width="300" controls autoplay muted loop>
							<source src="./resources/videos/media8.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</center>
				</td>
				<td>
					<center>
						<video width="300" controls autoplay muted loop>
							<source src="./resources/videos/media9.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</center>
				</td>
				<td>
					<center>
						<video width="300" controls autoplay muted loop>
							<source src="./resources/videos/media19.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</center>
				</td>
			</tr>
			<tr>
				<td>
					<center>
						<video width="300" controls autoplay muted loop>
							<source src="./resources/videos/media20.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</center>
				</td>
				<td>
					<center>
						<video width="300" controls autoplay muted loop>
							<source src="./resources/videos/media21.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</center>
				</td>
				<td>
					<center>
						<video width="300" controls autoplay muted loop>
							<source src="./resources/videos/media22.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</center>
				</td>
				<td>
					<center>
						<video width="300" controls autoplay muted loop>
							<source src="./resources/videos/media23.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</center>
				</td>
			</tr>
			<tr>
				<td>
					<center>
						<video width="300" controls autoplay muted loop>
							<source src="./resources/videos/media24.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</center>
				</td>
				<td>
					<center>
						<video width="300" controls autoplay muted loop>
							<source src="./resources/videos/media25.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</center>
				</td>
				<td>
					<center>
						<video width="300" controls autoplay muted loop>
							<source src="./resources/videos/media26.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</center>
				</td>
				<td>
					<center>
						<video width="300" controls autoplay muted loop>
							<source src="./resources/videos/media35.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</center>
				</td>
			</tr>
		</table>
	</center>


	<br>
	<hr>
	<table align=center width=1200px>
		<center>
			<h2 style="color:dimgrey;">Overall Architecture</h2>
		</center>
		<!-- <h2 style="color:dimgrey;">Overall Pipeline</h2> -->

		<!-- </table>
		<!-- <br> -->
		<!-- <table align=center width=1200px> -->
		<!-- <center>
			<h1>Overall Pipeline</h1>
		</center> -->
		<tr>
			
				<!-- <center> -->
			
				<!-- <br> -->
				<!-- <ul class="checkmark-list">
					<li>Previous urban scene reconstruction methods commonly rely on images collected from driving
						vehicles with cameras facing and moving forward.</li>
					<li>These methods can successfully synthesize from views similar to training camera trajectory.</li>
					<li>However, directing the novel view outside the training camera distribution does not guarantee
						on-par performance.</li>
					<li>We tackle the Extrapolated View Synthesis (EVS) problem on views such as looking left, right or
						downwards with respect to train distributions.</li>
					<li>(a) Illustration of Extrapolated View Synthesis (EVS) problem in urban scenes reconstructed with
						forward-facing cameras. </li>
					<li>(b) Qualitative comparison on EVS to baselines. Rendering quality on conventional test cameras
						is not necessarily preserved on EVS.</li>
				</ul> -->
				<!-- <center>
					<span style="font-size:16px"><b>We tackle the Extrapolated View Synthesis (EVS) problem on views such as looking left, right or downwards from train camera distributions.</b></span>
				</center> -->
				<!-- <ul class="checkmark-list">
					<li>We tackle the Extrapolated View Synthesis (EVS) problem on views such as <b>looking left, right or downwards from train camera distributions.</b></li>
				</ul> -->
				<h3 style="color:dimgrey;">Problem Definition</h3>
				<p>Given a source image and a driving video with F frames, our aim is to generate a video that:</p>
				<ul>
					<li>Incorporateing the foreground appearance from the source image.</li>
					<li>Following the pose of the driving video.</li>
					<li>Maintaining consistency in the background of the source image.</li>
				</ul>

				<h3 style="color:dimgrey;">Our approach</h3>
				<p>We propose TCAN, a novel human image animation framework based on the diffusion model that maintains temporal consistency and generalizes well to unseen domains. Our newly proposed modules are as follows:</p>
				<ul>
					<li><strong>Appearance-Pose Adaptation (APPA layer)</strong>: Preserving the appearance of the source image while maintaining pose information from frozen ControlNet.</li>
					<li><strong>Temporal ControlNet</strong>: Preventing the generated video from collapsing due to abrupt and erroneous pose changes</li>
					<li><strong>Pose-driven Temperature Map</strong>: Reducing the flickering in the static region by smoothing the attention scores in the temporal layer at the inference stage.</li>
				</ul>

				<!-- <p>TCAN follows a two-stage training framework widely adopted in current diffusion-based video generation works:</p>
				<ul>
					<li>The first stage involves transferring the source image at the image level to match the pose of each frame in driving video (Appearance UNet and APPA layer are trained).</li>
					<li>The second stage only trains temporal layers that align such image-level features into a continuous video sequence (Temporal ControlNet and Temporal layers in SD U-Net are trained). </li>
				</ul> -->

									
				<!-- Neural rendering-based urban scene reconstruction methods commonly rely on images collected from driving vehicles with cameras facing and moving forward.
					Although these methods can successfully synthesize from views similar to training camera trajectory,
					directing the novel view outside the training camera distribution does not guarantee on-par performance.
					In this paper, we tackle the Extrapolated View Synthesis (EVS) problem by evaluating the reconstructions
					on views such as looking left, right or downwards with respect to training camera distributions.					
					(a) Illustration of Extrapolated View Synthesis (EVS) problem in urban scenes
					reconstructed with forward-facing cameras. In contrast to conventional test cameras
					similar to training camera poses, we evaluate view synthesis on cameras distant from
					training camera distribution. (b) Qualitative comparison on EVS to baselines. Render-
					ing quality on conventional test cameras is not necessarily preserved on EVS. -->
			</td>
			<!-- </center> -->


			</td>
		</tr>
		<tr>
			<td>
				<br>
			</td>
		</tr>
		<tr>
			<!-- <td align=center width=1200px> -->
			<td>
				<center>
					<td><img class="round" style="width:1200px" src="./resources/images/overview_v4.jpg" /></td>
				</center>
			</td>
		</tr>
	</table>
</html>